{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-76181a9bcd6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_lenet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_from_json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0merror_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "A sample to generate adversarial examples.\n",
    "@author: Ying Meng (y(dot)meng201011(at)gmail(dot)com)\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from utils.model import load_lenet\n",
    "from utils.file import load_from_json\n",
    "from utils.metrics import error_rate\n",
    "from attacks.attack import generate\n",
    "\n",
    "\n",
    "def generate_ae(model, data, labels, attack_configs, save=False, output_dir=None):\n",
    "    \"\"\"\n",
    "    Generate adversarial examples\n",
    "    :param model: WeakDefense. The targeted model.\n",
    "    :param data: array. The benign samples to generate adversarial for.\n",
    "    :param labels: array or list. The true labels.\n",
    "    :param attack_configs: dictionary. Attacks and corresponding settings.\n",
    "    :param save: boolean. True, if save the adversarial examples.\n",
    "    :param output_dir: str or path. Location to save the adversarial examples.\n",
    "        It cannot be None when save is True.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    img_rows, img_cols = data.shape[1], data.shape[2]\n",
    "    num_attacks = attack_configs.get(\"num_attacks\")\n",
    "    data_loader = (data, labels)\n",
    "\n",
    "    if len(labels.shape) > 1:\n",
    "        labels = np.asarray([np.argmax(p) for p in labels])\n",
    "\n",
    "    # generate attacks one by one\n",
    "    for id in range(num_attacks):\n",
    "        key = \"configs{}\".format(id)\n",
    "        data_adv = generate(model=model,\n",
    "                            data_loader=data_loader,\n",
    "                            attack_args=attack_configs.get(key)\n",
    "                            )\n",
    "        # predict the adversarial examples\n",
    "        predictions = model.predict(data_adv)\n",
    "        predictions = np.asarray([np.argmax(p) for p in predictions])\n",
    "\n",
    "        err = error_rate(y_pred=predictions, y_true=labels)\n",
    "        print(\">>> error rate:\", err)\n",
    "\n",
    "        # plotting some examples\n",
    "        num_plotting = min(data.shape[0], 0)\n",
    "        for i in range(num_plotting):\n",
    "            img = data_adv[i].reshape((img_rows, img_cols))\n",
    "            plt.imshow(img, cmap='gray')\n",
    "            title = '{}: {}->{}'.format(attack_configs.get(key).get(\"description\"),\n",
    "                                        labels[i],\n",
    "                                        predictions[i]\n",
    "                                        )\n",
    "            plt.title(title)\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "\n",
    "        # save the adversarial example\n",
    "        if save:\n",
    "            if output_dir is None:\n",
    "                raise ValueError(\"Cannot save images to a none path.\")\n",
    "            # save with a random name\n",
    "            file = os.path.join(output_dir, \"{}.npy\".format(time.monotonic()))\n",
    "            print(\"Save the adversarial examples to file [{}].\".format(file))\n",
    "            np.save(file, data_adv)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description=\"\")\n",
    "\n",
    "    parser.add_argument('-m', '--model-configs', required=False,\n",
    "                        default='../configs/demo/model-mnist.json',\n",
    "                        help='Folder where models stored in.')\n",
    "    parser.add_argument('-d', '--data-configs', required=False,\n",
    "                        default='../configs/demo/data-mnist.json',\n",
    "                        help='Folder where test data stored in.')\n",
    "    parser.add_argument('-a', '--attack-configs', required=False,\n",
    "                        default='../configs/demo/attack-zk-mnist.json',\n",
    "                        help='Folder where test data stored in.')\n",
    "    parser.add_argument('-o', '--output-root', required=False,\n",
    "                        default='results',\n",
    "                        help='Folder for outputs.')\n",
    "    parser.add_argument('--debug', required=False, default=True)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    print(\"------AUGMENT SUMMARY-------\")\n",
    "    print(\"MODEL CONFIGS:\", args.model_configs)\n",
    "    print(\"DATA CONFIGS:\", args.data_configs)\n",
    "    print(\"ATTACK CONFIGS:\", args.attack_configs)\n",
    "    print(\"OUTPUT ROOT:\", args.output_root)\n",
    "    print(\"DEBUGGING MODE:\", args.debug)\n",
    "    print('----------------------------\\n')\n",
    "\n",
    "    # parse configurations (into a dictionary) from json file\n",
    "    model_configs = load_from_json(args.model_configs)\n",
    "    data_configs = load_from_json(args.data_configs)\n",
    "    attack_configs = load_from_json(args.attack_configs)\n",
    "\n",
    "    # load the targeted model\n",
    "    model_file = os.path.join(model_configs.get(\"dir\"), model_configs.get(\"um_file\"))\n",
    "    target = load_lenet(file=model_file, wrap=True)\n",
    "\n",
    "    # load the benign samples\n",
    "    data_file = os.path.join(data_configs.get('dir'), data_configs.get('bs_file'))\n",
    "    data_bs = np.load(data_file)\n",
    "    # load the corresponding true labels\n",
    "    label_file = os.path.join(data_configs.get('dir'), data_configs.get('label_file'))\n",
    "    labels = np.load(label_file)\n",
    "\n",
    "    # generate adversarial examples for a small subset\n",
    "    data_bs = data_bs[:10]\n",
    "    labels = labels[:10]\n",
    "    generate_ae(model=target, data=data_bs, labels=labels, attack_configs=attack_configs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
