{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'C:\\\\Users\\\\codyi\\\\Repositories\\\\project-athena\\\\Task1_update\\\\scripts\\\\cody_scripts', 'C:\\\\Users\\\\codyi\\\\anaconda3\\\\envs\\\\athena\\\\python37.zip', 'C:\\\\Users\\\\codyi\\\\anaconda3\\\\envs\\\\athena\\\\DLLs', 'C:\\\\Users\\\\codyi\\\\anaconda3\\\\envs\\\\athena\\\\lib', 'C:\\\\Users\\\\codyi\\\\anaconda3\\\\envs\\\\athena', 'C:\\\\Users\\\\codyi\\\\anaconda3\\\\envs\\\\athena\\\\lib\\\\site-packages', 'C:\\\\Users\\\\codyi\\\\anaconda3\\\\envs\\\\athena\\\\lib\\\\site-packages\\\\win32', 'C:\\\\Users\\\\codyi\\\\anaconda3\\\\envs\\\\athena\\\\lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\codyi\\\\anaconda3\\\\envs\\\\athena\\\\lib\\\\site-packages\\\\Pythonwin', 'C:\\\\Users\\\\codyi\\\\anaconda3\\\\envs\\\\athena\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\codyi\\\\.ipython', 'C:\\\\Users\\\\codyi\\\\Repositories\\\\project-athena\\\\src']\n"
     ]
    }
   ],
   "source": [
    "## Notebook by Ying Meng, (from notebooks/tasks/Task1_GenerateAEs_ZeroKnowledgeModel)\n",
    "## Modified by Cody Shearer\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../../../src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "print(sys.path)\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Prepare a smaller dataset for your experiment\n",
    "\n",
    "* python example: `tutorials/subsamples.py`\n",
    "* api: `utils.data.subsampling`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data import subsampling\n",
    "from utils.file import load_from_json\n",
    "\n",
    "# load the configurations for the experiment\n",
    "data_configs = load_from_json(\"../../configs/BIM/data-bim-mnist.json\")\n",
    "output_root = \"../../data\"\n",
    "\n",
    "# load the full-sized benign samples\n",
    "file = os.path.join(data_configs.get('dir'), data_configs.get('bs_file'))\n",
    "X_bs = np.load(file)\n",
    "\n",
    "# load the corresponding true labels\n",
    "file = os.path.join(data_configs.get('dir'), data_configs.get('label_file'))\n",
    "labels = np.load(file)\n",
    "\n",
    "# get random subsamples\n",
    "# for MNIST, num_classes is 10\n",
    "# files \"subsamples-mnist-ratio_0.1-xxxxxx.npy\" and \"sublabels-mnist-ratio_0.1-xxxxxx.npy\"\n",
    "# will be generated and saved at \"/results\" folder, where \"xxxxxx\" are timestamps.\n",
    "\n",
    "subsamples, sublabels = subsampling(data=X_bs,\n",
    "                                    labels=labels,\n",
    "                                    num_classes=10,\n",
    "                                    filepath=output_root,\n",
    "                                    filename='mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the json file accordingly\n",
    "\n",
    "1. Copy and paste the generated subsamples to the right place (i.e., defined by `\"dir\"` in `data-mnist.json`).\n",
    "2. In the `data-mnist.json`, replace the value of `\"bs_file\"` with the `\"subsamples-mnist-ratio_0.1-xxxxxx.npy\"` and the value of `\"label_file\"` with the `\"sublabels-mnist-ratio_0.1-xxxxxx.npy\"`.\n",
    "\n",
    "# Generate adversarial examples\n",
    "We use `FGSM` as the example.\n",
    "* python example: `tutorials/craft_adversarial_examples.py`\n",
    "* main api: `attacks.attack.generate`\n",
    "* check tunable parameters for each attack in file `attacks/attack.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from tutorials/craft_adversarial_examples.py\n",
    "def generate_ae(model, data, labels, attack_configs, save=False, output_dir=None):\n",
    "    \"\"\"\n",
    "    Generate adversarial examples\n",
    "    :param model: WeakDefense. The targeted model.\n",
    "    :param data: array. The benign samples to generate adversarial for.\n",
    "    :param labels: array or list. The true labels.\n",
    "    :param attack_configs: dictionary. Attacks and corresponding settings.\n",
    "    :param save: boolean. True, if save the adversarial examples.\n",
    "    :param output_dir: str or path. Location to save the adversarial examples.\n",
    "        It cannot be None when save is True.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    img_rows, img_cols = data.shape[1], data.shape[2]\n",
    "    num_attacks = attack_configs.get(\"num_attacks\")\n",
    "    data_loader = (data, labels)\n",
    "\n",
    "    if len(labels.shape) > 1:\n",
    "        labels = np.asarray([np.argmax(p) for p in labels])\n",
    "\n",
    "    # generate attacks one by one\n",
    "    for id in range(num_attacks):\n",
    "        key = \"configs{}\".format(id)\n",
    "        data_adv = generate(model=model,\n",
    "                            data_loader=data_loader,\n",
    "                            attack_args=attack_configs.get(key)\n",
    "                            )\n",
    "        # predict the adversarial examples\n",
    "        predictions = model.predict(data_adv)\n",
    "        predictions = np.asarray([np.argmax(p) for p in predictions])\n",
    "\n",
    "        err = error_rate(y_pred=predictions, y_true=labels)\n",
    "        print(\">>> error rate:\", err)\n",
    "\n",
    "        # plotting some examples\n",
    "        num_plotting = min(data.shape[0], 2)\n",
    "        for i in range(num_plotting):\n",
    "            img = data_adv[i].reshape((img_rows, img_cols))\n",
    "            plt.imshow(img, cmap='gray')\n",
    "            title = '{}: {}->{}'.format(attack_configs.get(key).get(\"description\"),\n",
    "                                        labels[i],\n",
    "                                        predictions[i]\n",
    "                                        )\n",
    "            plt.title(title)\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "\n",
    "        # save the adversarial example\n",
    "        if save:\n",
    "            if output_dir is None:\n",
    "                raise ValueError(\"Cannot save images to a none path.\")\n",
    "            # save with a random name\n",
    "            file = os.path.join(output_dir,\n",
    "                \"AE-mnist-cnn-clean-bim_eps{}_maxiter{}.npy\".format(\n",
    "                    attack_configs.get(key).get(\"eps\"),\n",
    "                    attack_configs.get(key).get(\"max_iter\"))\n",
    "                )\n",
    "            print(\"Save the adversarial examples to file [{}].\".format(file))\n",
    "            np.save(file, data_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Loading model [../../../models/cnn/model-mnist-cnn-clean.h5]...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# loading experiment configurations\n",
    "model_configs = load_from_json(\"../../configs/BIM/model-mnist.json\")\n",
    "data_configs = load_from_json(\"../../configs/BIM/data-bim-mnist.json\")\n",
    "attack_configs = load_from_json(\"../../configs/BIM/attack-bim-mnist.json\")\n",
    "\n",
    "# load labels\n",
    "label_file = os.path.join(data_configs.get('dir'), data_configs.get('label_file'))\n",
    "labels = np.load(label_file)\n",
    "labels = np.asarray([np.argmax(p) for p in labels])\n",
    "\n",
    "# load list of AEs\n",
    "ae_list = data_configs.get('ae_files')\n",
    "\n",
    "# load the benign samples to get dimensions of images\n",
    "data_file = os.path.join(data_configs.get('dir'), data_configs.get('bs_file'))\n",
    "data_bs = np.load(data_file)\n",
    "img_rows, img_cols = data_bs.shape[1], data_bs.shape[2]\n",
    "\n",
    "# load the targeted model\n",
    "model_file = os.path.join(model_configs.get(\"dir\"), model_configs.get(\"um_file\"))\n",
    "model = load_lenet(file=model_file, wrap=True)\n",
    "\n",
    "fig, axs = plt.subplots(3,3,\n",
    "                        facecolor='w',\n",
    "                        figsize=(8,8), dpi=102)\n",
    "\n",
    "fig.subplots_adjust(hspace=0, wspace=0)\n",
    "\n",
    "fig.suptitle('Example BIM AEs')\n",
    "\n",
    "rows = ['epsilon={}'.format(col) for col in [0.1, 0.2, 0.3]]\n",
    "cols = ['max_iter={}'.format(row) for row in [50, 60, 70]]\n",
    "\n",
    "# set labels for columns\n",
    "for ax, col in zip(axs[0], cols):\n",
    "    ax.set_title(col)\n",
    "\n",
    "# set labels for rows\n",
    "for ax, row in zip(axs[:,0], rows):\n",
    "    ax.set_ylabel(row, rotation=90, size='large')\n",
    "\n",
    "# plot some adversarial examples and their predictions\n",
    "for ae_ind, ax in zip(range(len(ae_list)), axs.flatten()):\n",
    "    # load AE image\n",
    "    ae_file = os.path.join(data_configs.get('dir'), ae_list[ae_ind])\n",
    "    data_adv = np.load(ae_file)\n",
    "    predictions = model.predict(data_adv)\n",
    "    predictions = np.asarray([np.argmax(p) for p in predictions])\n",
    "    img = data_adv[0].reshape((img_rows, img_cols))\n",
    "    # add AE image\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    # turn off useless ticks and tick labels\n",
    "    plt.setp(ax.get_xticklabels(), visible=False)\n",
    "    plt.setp(ax.get_yticklabels(), visible=False)\n",
    "    ax.tick_params(axis='both', which='both', length=0)\n",
    "    \n",
    "fig.savefig('../../figures/example_BIM_AEs.png', dpi=fig.dpi, pad_inches=0, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the generated adversarial examples in json\n",
    "\n",
    "* Either add an item for the generated AEs. e.g., assume that we named the generated AE as `\"fgsm_eps0.3.npy\"`, then add the item as below example, then get your AE list by `data_configs.get(\"task1_aes\")`.\n",
    "\n",
    "```\n",
    "\"task1_aes\" : [\n",
    "                  \"fgsm_eps0.3.npy\"\n",
    "              ]\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "2. Or, create a new json file similar to `\"data-mnist.json\"`, and replace the whole list for `\"ae_files\"` with your own list.\n",
    "\n",
    "# Evaluate the generated AEs\n",
    "* python example: `tutorials/eval_model.py`\n",
    "* api: `utils.metrics.error_rate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.model import load_pool\n",
    "from utils.metrics import error_rate, get_corrections\n",
    "from models.athena import Ensemble, ENSEMBLE_STRATEGY\n",
    "import numpy as np\n",
    "\n",
    "# copied from tutorials/eval_model.py\n",
    "def evaluate(trans_configs, model_configs,\n",
    "             data_configs):\n",
    "    \"\"\"\n",
    "    Apply transformation(s) on images.\n",
    "    :param trans_configs: dictionary. The collection of the parameterized transformations to test.\n",
    "        in the form of\n",
    "        { configsx: {\n",
    "            param: value,\n",
    "            }\n",
    "        }\n",
    "        The key of a configuration is 'configs'x, where 'x' is the id of corresponding weak defense.\n",
    "    :param model_configs:  dictionary. Defines model related information.\n",
    "        Such as, location, the undefended model, the file format, etc.\n",
    "    :param data_configs: dictionary. Defines data related information.\n",
    "        Such as, location, the file for the true labels, the file for the benign samples,\n",
    "        the files for the adversarial examples, etc.\n",
    "    :param save: boolean. Save the transformed sample or not.\n",
    "    :param output_dir: path or str. The location to store the transformed samples.\n",
    "        It cannot be None when save is True.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Load the baseline defense (PGD-ADT model)\n",
    "    baseline = load_lenet(file=model_configs.get('pgd_trained'), trans_configs=None,\n",
    "                                  use_logits=False, wrap=False)\n",
    "\n",
    "    # get the undefended model (UM)\n",
    "    file = os.path.join(model_configs.get('dir'), model_configs.get('um_file'))\n",
    "    undefended = load_lenet(file=file,\n",
    "                            trans_configs=trans_configs.get('configs0'),\n",
    "                            wrap=True)\n",
    "    print(\">>> um:\", type(undefended))\n",
    "\n",
    "    # load weak defenses into a pool\n",
    "    pool, _ = load_pool(trans_configs=trans_configs,\n",
    "                        model_configs=model_configs,\n",
    "                        active_list=True,\n",
    "                        wrap=True)\n",
    "    # create an AVEP ensemble from the WD pool\n",
    "    wds = list(pool.values())\n",
    "    print(\">>> wds:\", type(wds), type(wds[0]))\n",
    "    ensemble = Ensemble(classifiers=wds, strategy=ENSEMBLE_STRATEGY.AVEP.value)\n",
    "\n",
    "    # load the benign samples\n",
    "    bs_file = os.path.join(data_configs.get('dir'), data_configs.get('bs_file'))\n",
    "    x_bs = np.load(bs_file)\n",
    "    img_rows, img_cols = x_bs.shape[1], x_bs.shape[2]\n",
    "\n",
    "    # load the corresponding true labels\n",
    "    label_file = os.path.join(data_configs.get('dir'), data_configs.get('label_file'))\n",
    "    labels = np.load(label_file)\n",
    "\n",
    "    # get indices of benign samples that are correctly classified by the targeted model\n",
    "    print(\">>> Evaluating UM on [{}], it may take a while...\".format(bs_file))\n",
    "    pred_bs = undefended.predict(x_bs)\n",
    "    corrections = get_corrections(y_pred=pred_bs, y_true=labels)\n",
    "\n",
    "    # Evaluate AEs.\n",
    "    ae_list = data_configs.get('ae_files')\n",
    "    for ae_ind in range(len(ae_list)):\n",
    "        results = {}\n",
    "        ae_file = os.path.join(data_configs.get('dir'), ae_list[ae_ind])\n",
    "        print(ae_list[ae_ind])\n",
    "        print(ae_file)\n",
    "        x_adv = np.load(ae_file)\n",
    "\n",
    "        # evaluate the undefended model on the AE\n",
    "        print(\">>> Evaluating UM on [{}], it may take a while...\".format(ae_file))\n",
    "        pred_adv_um = undefended.predict(x_adv)\n",
    "        err_um = error_rate(y_pred=pred_adv_um, y_true=labels, correct_on_bs=corrections)\n",
    "        # track the result\n",
    "        results['UM'] = err_um\n",
    "\n",
    "        # evaluate the ensemble on the AE\n",
    "        print(\">>> Evaluating ensemble on [{}], it may take a while...\".format(ae_file))\n",
    "        pred_adv_ens = ensemble.predict(x_adv)\n",
    "        err_ens = error_rate(y_pred=pred_adv_ens, y_true=labels, correct_on_bs=corrections)\n",
    "        # track the result\n",
    "        results['Ensemble'] = err_ens\n",
    "\n",
    "        # evaluate the baseline on the AE\n",
    "        print(\">>> Evaluating baseline model on [{}], it may take a while...\".format(ae_file))\n",
    "        pred_adv_bl = baseline.predict(x_adv)\n",
    "        err_bl = error_rate(y_pred=pred_adv_bl, y_true=labels, correct_on_bs=corrections)\n",
    "        # track the result\n",
    "        results['PGD-ADT'] = err_bl\n",
    "\n",
    "        # TODO: collect and dump the evaluation results to file(s) such that you can analyze them laterr\n",
    "        np.savez_compressed('../../results/BIM.npz', results)\n",
    "        print(\">>> Evaluations on [{}]:\\n{}\".format(ae_file, results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Loading model [../../../models/baseline/advTrained-mnist-adtC.h5]...\n",
      ">>> Loading model [../../../models/cnn/model-mnist-cnn-clean.h5]...\n",
      ">>> um: <class 'models.keraswrapper.WeakDefense'>\n",
      ">>> Loading model [../../../models/cnn/model-mnist-cnn-clean.h5]...\n",
      ">>> Loading model [../../../models/cnn/model-mnist-cnn-rotate90.h5]...\n",
      ">>> Loading model [../../../models/cnn/model-mnist-cnn-shift_left.h5]...\n",
      ">>> Loading model [../../../models/cnn/model-mnist-cnn-flip_horizontal.h5]...\n",
      ">>> Loading model [../../../models/cnn/model-mnist-cnn-affine_vertical_compress.h5]...\n",
      ">>> Loading model [../../../models/cnn/model-mnist-cnn-morph_erosion.h5]...\n",
      ">>> Loading model [../../../models/cnn/model-mnist-cnn-augment_samplewise_std_norm.h5]...\n",
      ">>> Loading model [../../../models/cnn/model-mnist-cnn-cartoon_mean_type1.h5]...\n",
      ">>> Loading model [../../../models/cnn/model-mnist-cnn-quant_4_clusters.h5]...\n",
      ">>> Loading model [../../../models/cnn/model-mnist-cnn-distort_x.h5]...\n",
      ">>> Loading model [../../../models/cnn/model-mnist-cnn-noise_gaussian.h5]...\n",
      ">>> Loading model [../../../models/cnn/model-mnist-cnn-filter_sobel.h5]...\n",
      ">>> Loading model [../../../models/cnn/model-mnist-cnn-compress_jpeg_quality_80.h5]...\n",
      ">>> Loading model [../../../models/cnn/model-mnist-cnn-denoise_tv_chambolle.h5]...\n",
      ">>> Loading model [../../../models/cnn/model-mnist-cnn-geo_swirl.h5]...\n",
      ">>> Loading model [../../../models/cnn/model-mnist-cnn-seg_gradient.h5]...\n",
      ">>> Loaded 16 models.\n",
      ">>> wds: <class 'list'> <class 'models.keraswrapper.WeakDefense'>\n",
      ">>> Evaluating UM on [../../data/subsamples-1000-ratio_0.1-398037.171.npy], it may take a while...\n",
      "AE-mnist-cnn-clean-bim_eps0.1_maxiter50.npy\n",
      "../../data/AE-mnist-cnn-clean-bim_eps0.1_maxiter50.npy\n",
      ">>> Evaluating UM on [../../data/AE-mnist-cnn-clean-bim_eps0.1_maxiter50.npy], it may take a while...\n",
      "Y predict shape:  1000\n",
      "989\n",
      ">>> Evaluating ensemble on [../../data/AE-mnist-cnn-clean-bim_eps0.1_maxiter50.npy], it may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\codyi\\Repositories\\project-athena\\src\\models\\image_processor.py:73: UserWarning: Possible precision loss converting image of type float32 to uint8 as required by rank filters. Convert manually using skimage.util.img_as_ubyte to silence this warning.\n",
      "  return _segment_trans(X, trans_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y predict shape:  1000\n",
      "989\n",
      ">>> Evaluating baseline model on [../../data/AE-mnist-cnn-clean-bim_eps0.1_maxiter50.npy], it may take a while...\n",
      "Y predict shape:  1000\n",
      "989\n",
      ">>> Evaluations on [../../data/AE-mnist-cnn-clean-bim_eps0.1_maxiter50.npy]:\n",
      "{'UM': 0.9059656218402427, 'Ensemble': 0.017189079878665317, 'PGD-ADT': 0.025278058645096056}\n",
      "AE-mnist-cnn-clean-bim_eps0.1_maxiter60.npy\n",
      "../../data/AE-mnist-cnn-clean-bim_eps0.1_maxiter60.npy\n",
      ">>> Evaluating UM on [../../data/AE-mnist-cnn-clean-bim_eps0.1_maxiter60.npy], it may take a while...\n",
      "Y predict shape:  1000\n",
      "989\n",
      ">>> Evaluating ensemble on [../../data/AE-mnist-cnn-clean-bim_eps0.1_maxiter60.npy], it may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\codyi\\Repositories\\project-athena\\src\\models\\image_processor.py:73: UserWarning: Possible precision loss converting image of type float32 to uint8 as required by rank filters. Convert manually using skimage.util.img_as_ubyte to silence this warning.\n",
      "  return _segment_trans(X, trans_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y predict shape:  1000\n",
      "989\n",
      ">>> Evaluating baseline model on [../../data/AE-mnist-cnn-clean-bim_eps0.1_maxiter60.npy], it may take a while...\n",
      "Y predict shape:  1000\n",
      "989\n",
      ">>> Evaluations on [../../data/AE-mnist-cnn-clean-bim_eps0.1_maxiter60.npy]:\n",
      "{'UM': 0.910010111223458, 'Ensemble': 0.017189079878665317, 'PGD-ADT': 0.025278058645096056}\n",
      "AE-mnist-cnn-clean-bim_eps0.1_maxiter70.npy\n",
      "../../data/AE-mnist-cnn-clean-bim_eps0.1_maxiter70.npy\n",
      ">>> Evaluating UM on [../../data/AE-mnist-cnn-clean-bim_eps0.1_maxiter70.npy], it may take a while...\n",
      "Y predict shape:  1000\n",
      "989\n",
      ">>> Evaluating ensemble on [../../data/AE-mnist-cnn-clean-bim_eps0.1_maxiter70.npy], it may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\codyi\\Repositories\\project-athena\\src\\models\\image_processor.py:73: UserWarning: Possible precision loss converting image of type float32 to uint8 as required by rank filters. Convert manually using skimage.util.img_as_ubyte to silence this warning.\n",
      "  return _segment_trans(X, trans_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y predict shape:  1000\n",
      "989\n",
      ">>> Evaluating baseline model on [../../data/AE-mnist-cnn-clean-bim_eps0.1_maxiter70.npy], it may take a while...\n",
      "Y predict shape:  1000\n",
      "989\n",
      ">>> Evaluations on [../../data/AE-mnist-cnn-clean-bim_eps0.1_maxiter70.npy]:\n",
      "{'UM': 0.9180990899898888, 'Ensemble': 0.017189079878665317, 'PGD-ADT': 0.025278058645096056}\n",
      "AE-mnist-cnn-clean-bim_eps0.2_maxiter50.npy\n",
      "../../data/AE-mnist-cnn-clean-bim_eps0.2_maxiter50.npy\n",
      ">>> Evaluating UM on [../../data/AE-mnist-cnn-clean-bim_eps0.2_maxiter50.npy], it may take a while...\n",
      "Y predict shape:  1000\n",
      "989\n",
      ">>> Evaluating ensemble on [../../data/AE-mnist-cnn-clean-bim_eps0.2_maxiter50.npy], it may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\codyi\\Repositories\\project-athena\\src\\models\\image_processor.py:73: UserWarning: Possible precision loss converting image of type float32 to uint8 as required by rank filters. Convert manually using skimage.util.img_as_ubyte to silence this warning.\n",
      "  return _segment_trans(X, trans_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y predict shape:  1000\n",
      "989\n",
      ">>> Evaluating baseline model on [../../data/AE-mnist-cnn-clean-bim_eps0.2_maxiter50.npy], it may take a while...\n",
      "Y predict shape:  1000\n",
      "989\n",
      ">>> Evaluations on [../../data/AE-mnist-cnn-clean-bim_eps0.2_maxiter50.npy]:\n",
      "{'UM': 0.9888776541961577, 'Ensemble': 0.09706774519716886, 'PGD-ADT': 0.08088978766430738}\n",
      "AE-mnist-cnn-clean-bim_eps0.2_maxiter60.npy\n",
      "../../data/AE-mnist-cnn-clean-bim_eps0.2_maxiter60.npy\n",
      ">>> Evaluating UM on [../../data/AE-mnist-cnn-clean-bim_eps0.2_maxiter60.npy], it may take a while...\n",
      "Y predict shape:  1000\n",
      "989\n",
      ">>> Evaluating ensemble on [../../data/AE-mnist-cnn-clean-bim_eps0.2_maxiter60.npy], it may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\codyi\\Repositories\\project-athena\\src\\models\\image_processor.py:73: UserWarning: Possible precision loss converting image of type float32 to uint8 as required by rank filters. Convert manually using skimage.util.img_as_ubyte to silence this warning.\n",
      "  return _segment_trans(X, trans_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y predict shape:  1000\n",
      "989\n",
      ">>> Evaluating baseline model on [../../data/AE-mnist-cnn-clean-bim_eps0.2_maxiter60.npy], it may take a while...\n",
      "Y predict shape:  1000\n",
      "989\n",
      ">>> Evaluations on [../../data/AE-mnist-cnn-clean-bim_eps0.2_maxiter60.npy]:\n",
      "{'UM': 0.9888776541961577, 'Ensemble': 0.09605662285136501, 'PGD-ADT': 0.07987866531850354}\n",
      "AE-mnist-cnn-clean-bim_eps0.2_maxiter70.npy\n",
      "../../data/AE-mnist-cnn-clean-bim_eps0.2_maxiter70.npy\n",
      ">>> Evaluating UM on [../../data/AE-mnist-cnn-clean-bim_eps0.2_maxiter70.npy], it may take a while...\n",
      "Y predict shape:  1000\n",
      "989\n",
      ">>> Evaluating ensemble on [../../data/AE-mnist-cnn-clean-bim_eps0.2_maxiter70.npy], it may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\codyi\\Repositories\\project-athena\\src\\models\\image_processor.py:73: UserWarning: Possible precision loss converting image of type float32 to uint8 as required by rank filters. Convert manually using skimage.util.img_as_ubyte to silence this warning.\n",
      "  return _segment_trans(X, trans_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y predict shape:  1000\n",
      "989\n",
      ">>> Evaluating baseline model on [../../data/AE-mnist-cnn-clean-bim_eps0.2_maxiter70.npy], it may take a while...\n",
      "Y predict shape:  1000\n",
      "989\n",
      ">>> Evaluations on [../../data/AE-mnist-cnn-clean-bim_eps0.2_maxiter70.npy]:\n",
      "{'UM': 0.9888776541961577, 'Ensemble': 0.0980788675429727, 'PGD-ADT': 0.07987866531850354}\n",
      "AE-mnist-cnn-clean-bim_eps0.3_maxiter50.npy\n",
      "../../data/AE-mnist-cnn-clean-bim_eps0.3_maxiter50.npy\n",
      ">>> Evaluating UM on [../../data/AE-mnist-cnn-clean-bim_eps0.3_maxiter50.npy], it may take a while...\n",
      "Y predict shape:  1000\n",
      "989\n",
      ">>> Evaluating ensemble on [../../data/AE-mnist-cnn-clean-bim_eps0.3_maxiter50.npy], it may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\codyi\\Repositories\\project-athena\\src\\models\\image_processor.py:73: UserWarning: Possible precision loss converting image of type float32 to uint8 as required by rank filters. Convert manually using skimage.util.img_as_ubyte to silence this warning.\n",
      "  return _segment_trans(X, trans_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y predict shape:  1000\n",
      "989\n",
      ">>> Evaluating baseline model on [../../data/AE-mnist-cnn-clean-bim_eps0.3_maxiter50.npy], it may take a while...\n",
      "Y predict shape:  1000\n",
      "989\n",
      ">>> Evaluations on [../../data/AE-mnist-cnn-clean-bim_eps0.3_maxiter50.npy]:\n",
      "{'UM': 0.9888776541961577, 'Ensemble': 0.44691607684529827, 'PGD-ADT': 0.3619817997977755}\n",
      "AE-mnist-cnn-clean-bim_eps0.3_maxiter60.npy\n",
      "../../data/AE-mnist-cnn-clean-bim_eps0.3_maxiter60.npy\n",
      ">>> Evaluating UM on [../../data/AE-mnist-cnn-clean-bim_eps0.3_maxiter60.npy], it may take a while...\n",
      "Y predict shape:  1000\n",
      "989\n",
      ">>> Evaluating ensemble on [../../data/AE-mnist-cnn-clean-bim_eps0.3_maxiter60.npy], it may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\codyi\\Repositories\\project-athena\\src\\models\\image_processor.py:73: UserWarning: Possible precision loss converting image of type float32 to uint8 as required by rank filters. Convert manually using skimage.util.img_as_ubyte to silence this warning.\n",
      "  return _segment_trans(X, trans_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y predict shape:  1000\n",
      "989\n",
      ">>> Evaluating baseline model on [../../data/AE-mnist-cnn-clean-bim_eps0.3_maxiter60.npy], it may take a while...\n",
      "Y predict shape:  1000\n",
      "989\n",
      ">>> Evaluations on [../../data/AE-mnist-cnn-clean-bim_eps0.3_maxiter60.npy]:\n",
      "{'UM': 0.9888776541961577, 'Ensemble': 0.455005055611729, 'PGD-ADT': 0.3640040444893832}\n",
      "AE-mnist-cnn-clean-bim_eps0.3_maxiter70.npy\n",
      "../../data/AE-mnist-cnn-clean-bim_eps0.3_maxiter70.npy\n",
      ">>> Evaluating UM on [../../data/AE-mnist-cnn-clean-bim_eps0.3_maxiter70.npy], it may take a while...\n",
      "Y predict shape:  1000\n",
      "989\n",
      ">>> Evaluating ensemble on [../../data/AE-mnist-cnn-clean-bim_eps0.3_maxiter70.npy], it may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\codyi\\Repositories\\project-athena\\src\\models\\image_processor.py:73: UserWarning: Possible precision loss converting image of type float32 to uint8 as required by rank filters. Convert manually using skimage.util.img_as_ubyte to silence this warning.\n",
      "  return _segment_trans(X, trans_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y predict shape:  1000\n",
      "989\n",
      ">>> Evaluating baseline model on [../../data/AE-mnist-cnn-clean-bim_eps0.3_maxiter70.npy], it may take a while...\n",
      "Y predict shape:  1000\n",
      "989\n",
      ">>> Evaluations on [../../data/AE-mnist-cnn-clean-bim_eps0.3_maxiter70.npy]:\n",
      "{'UM': 0.9888776541961577, 'Ensemble': 0.448938321536906, 'PGD-ADT': 0.3579373104145602}\n"
     ]
    }
   ],
   "source": [
    "# load experiment configurations\n",
    "trans_configs = load_from_json(\"../../configs/BIM/athena-mnist.json\")\n",
    "model_configs = load_from_json(\"../../configs/BIM/model-mnist.json\")\n",
    "data_configs = load_from_json(\"../../configs/BIM/data-bim-mnist.json\")\n",
    "\n",
    "output_dir = \"../../results\"\n",
    "\n",
    "# evaluate\n",
    "evaluate(trans_configs=trans_configs,\n",
    "         model_configs=model_configs,\n",
    "         data_configs=data_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
